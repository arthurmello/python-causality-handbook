{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Matching\n",
    "\n",
    "## Que fait la régression après tout ?\n",
    "\n",
    "Comme nous l'avons vu jusqu'à présent, la régression fait un travail incroyable pour contrôler les variables supplémentaires lorsqu'on effectue une comparaison test vs contrôle. Si nous avons l'indépendance, $(Y_0, Y_1)\\perp T | X$, alors la régression peut identifier l'ATE en contrôlant pour X. La manière dont la régression fait cela est un peu magique. Pour en avoir une intuition, souvenons-nous du cas où toutes les variables X sont des variables fictives (dummy variables). Si c'est le cas, la régression partitionne les données en cellules fictives et calcule la différence moyenne entre le test et le contrôle. Cette différence de moyennes maintient les X constants, puisque nous le faisons dans une cellule fixe de X fictif. C'est comme si nous faisions $E[Y|T=1] - E[Y|T=0] | X=x$, où $x$ est une cellule fictive (toutes les variables fictives définies à 1, par exemple). La régression combine ensuite les estimations dans chacune des cellules pour produire un ATE final. Elle le fait en appliquant des poids aux cellules proportionnellement à la variance du traitement dans ce groupe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import graphviz as gr\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour donner un exemple, supposons que j'essaie d'estimer l'effet d'un médicament et que j'ai 6 hommes et 4 femmes. Ma variable de réponse est le nombre de jours d'hospitalisation et j'espère que mon médicament pourra réduire ce nombre. Chez les hommes, l'effet causal véritable est de -3, donc le médicament réduit la durée du séjour de 3 jours. Chez les femmes, il est de -2. Pour rendre les choses plus intéressantes, les hommes sont beaucoup plus touchés par cette maladie et restent plus longtemps à l'hôpital. Ils reçoivent également beaucoup plus le médicament. Un seul des 6 hommes ne reçoit pas le médicament. D'autre part, les femmes sont plus résistantes à cette maladie, donc elles restent moins longtemps à l'hôpital. 50 % des femmes reçoivent le médicament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_example = pd.DataFrame(dict(\n",
    "    sex= [\"M\",\"M\",\"M\",\"M\",\"M\",\"M\", \"W\",\"W\",\"W\",\"W\"],\n",
    "    drug=[1,1,1,1,1,0,  1,0,1,0],\n",
    "    days=[5,5,5,5,5,8,  2,4,2,4]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez qu'une simple comparaison entre le traitement et le contrôle donne un effet biaisé négativement, c'est-à-dire que le médicament semble moins efficace qu'il ne l'est réellement. Cela est attendu, puisque nous avons omis le facteur de confusion lié au sexe. Dans ce cas, l'ATE estimé est plus petit que le véritable ATE parce que les hommes reçoivent davantage le médicament et sont plus affectés par la maladie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1904761904761898"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_example.query(\"drug==1\")[\"days\"].mean() - drug_example.query(\"drug==0\")[\"days\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque l'effet réel pour les hommes est de -3 et l'effet réel pour les femmes est de -2, l'ATE devrait être\n",
    "\n",
    "$$\n",
    "ATE = \\dfrac{(-3*6) + (-2*4)}{10} = -2.6\n",
    "$$\n",
    "\n",
    "Cette estimation est réalisée en 1) partitionnant les données en cellules de confusion, dans ce cas, hommes et femmes, 2) estimant l'effet dans chaque cellule et 3) combinant les estimations avec une moyenne pondérée, où le poids est la taille de l'échantillon de la cellule ou du groupe de covariables. Si nous avions exactement le même nombre d'hommes et de femmes dans les données, l'estimation de l'ATE serait exactement au milieu de l'ATE des deux groupes, soit -2,5. Étant donné qu'il y a plus d'hommes que de femmes dans notre ensemble de données, l'estimation de l'ATE est un peu plus proche de l'ATE des hommes. Cela s'appelle une estimation non paramétrique, puisqu'elle ne repose sur aucune hypothèse concernant la façon dont les données ont été générées.\n",
    "\n",
    "Si nous contrôlons le sexe en utilisant la régression, nous ajouterons l'hypothèse de linéarité. La régression partitionnera également les données en hommes et femmes et estimera l'effet sur ces deux groupes. Jusqu'ici, tout va bien. Cependant, lorsqu'il s'agit de combiner l'effet sur chaque groupe, elle ne les pèse pas par la taille de l'échantillon. Au lieu de cela, la régression utilise des poids proportionnels à la variance du traitement dans ce groupe. Dans notre cas, la variance du traitement chez les hommes est plus petite que chez les femmes, puisque seul un homme est dans le groupe de contrôle. Pour être exact, la variance de T pour les hommes est de $0.139 = 1/6*(1 - 1/6)$ et pour les femmes est de $0.25 = 2/4*(1 - 2/4)$. Ainsi, la régression donnera un poids plus élevé aux femmes dans notre exemple et l'ATE sera un peu plus proche de l'ATE des femmes de -2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    7.5455</td> <td>    0.188</td> <td>   40.093</td> <td> 0.000</td> <td>    7.100</td> <td>    7.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(sex)[T.W]</th> <td>   -3.3182</td> <td>    0.176</td> <td>  -18.849</td> <td> 0.000</td> <td>   -3.734</td> <td>   -2.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drug</th>        <td>   -2.4545</td> <td>    0.188</td> <td>  -13.042</td> <td> 0.000</td> <td>   -2.900</td> <td>   -2.010</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('days ~ drug + C(sex)', data=drug_example).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce résultat est plus intuitif avec des variables fictives, mais, d'une manière étrange, la régression maintient également les variables continues constantes tout en estimant l'effet. De plus, avec des variables continues, l'ATE pointera dans la direction où les covariables ont plus de variance.\n",
    "\n",
    "Nous avons donc vu que la régression a ses particularités. Elle est linéaire, paramétrique, apprécie les caractéristiques à forte variance... Cela peut être bon ou mauvais, selon le contexte. C'est pourquoi il est important d'être conscient des autres techniques que nous pouvons utiliser pour contrôler les facteurs de confusion. Non seulement elles constituent un outil supplémentaire dans votre ceinture à outils causale, mais comprendre différentes manières de traiter les facteurs de confusion élargit notre compréhension du problème. Pour cette raison, je vous présente maintenant l'**Estimateur de Subclassification !**\n",
    "\n",
    "## L'Estimateur de Subclassification\n",
    "\n",
    "![img](./data/img/matching/explain.png)\n",
    "\n",
    "S'il y a un effet causal que nous voulons estimer, comme l'effet de la formation professionnelle sur les revenus, **et** que le traitement n'est pas attribué au hasard, nous devons faire attention aux facteurs de confusion. Il se pourrait que seules les personnes plus motivées suivent la formation et qu'elles auraient des revenus plus élevés indépendamment de la formation. Nous devons estimer l'effet du programme de formation au sein de petits groupes d'individus qui sont à peu près au même niveau de motivation et de tout autre facteur de confusion que nous pourrions avoir.\n",
    "\n",
    "Plus généralement, s'il y a un effet causal que nous voulons estimer, mais qu'il est difficile de le faire à cause de la confusion de certaines variables X, ce que nous devons faire est de faire la comparaison traitement vs contrôle au sein de petits groupes où X est le même. Si nous avons l'indépendance conditionnelle $(Y_0, Y_1)\\perp T | X$, alors nous pouvons écrire l'ATE comme suit.\n",
    "\n",
    "$$\n",
    "ATE = \\int(E[Y|X, T=1] - E[Y|X, T=0])dP(x)\n",
    "$$\n",
    "\n",
    "Ce que fait cette intégrale, c'est qu'elle parcourt tout l'espace de la distribution des caractéristiques X, calcule la différence de moyennes pour tous ces petits espaces et combine le tout en l'ATE. Une autre façon de voir cela est de penser à un ensemble discret de caractéristiques. Dans ce cas, nous pouvons dire que les caractéristiques X prennent K différentes cellules $\\{X_1, X_2, ..., X_k\\}$ et ce que nous faisons est de calculer l'effet du traitement dans chaque cellule et de les combiner dans l'ATE. Dans ce cas discret, en convertissant l'intégrale en une somme, nous pouvons dériver l'estimateur de subclassification.\n",
    "\n",
    "$$\n",
    "\\hat{ATE} = \\sum^K_{k=1}(\\bar{Y}_{k1} - \\bar{Y}_{k0}) * \\dfrac{N_k}{N}\n",
    "$$\n",
    "\n",
    "où la barre représente la moyenne du résultat pour les traités, $Y_{k1}$, et les non-traités, $Y_{k0}$, dans la cellule k et $N_{k}$ est le nombre d'observations dans cette même cellule. Comme vous pouvez le voir, nous calculons un ATE local pour chaque cellule et les combinons en utilisant une moyenne pondérée, où les poids sont la taille de l'échantillon de la cellule. Dans notre exemple de médicament ci-dessus, ce serait la première estimation, qui nous a donné -2,6.\n",
    "\n",
    "## Estimateur de Matching\n",
    "\n",
    "![img](./data/img/matching/its-a-match.png)\n",
    "\n",
    "L'estimateur de subclassification n'est pas beaucoup utilisé en pratique (nous verrons pourquoi sous peu, c'est à cause du fléau de la dimensionnalité), mais il nous donne une bonne intuition de ce que devrait faire un estimateur d'inférence causale, comment il devrait contrôler les facteurs de confusion. Cela nous permet d'explorer d'autres types d'estimateurs, comme l'estimateur de matching.\n",
    "\n",
    "L'idée est très similaire. Étant donné qu'un certain type de facteur de confusion X fait en sorte que les traités et les non-traités ne sont pas initialement comparables, je peux les rendre comparables en **appariant chaque unité traitée avec une unité non traitée similaire**. C'est comme si je trouvais un jumeau non traité pour chaque unité traitée. En faisant de telles comparaisons, les traités et les non-traités redeviennent comparables.\n",
    "\n",
    "À titre d'exemple, supposons que nous essayons d'estimer l'effet d'un programme de formation sur les revenus. Voici à quoi ressemblent les stagiaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>trainees</th>\n",
       "      <th>age</th>\n",
       "      <th>earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>17700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>14400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>20800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>28600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>21900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>28800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>20300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>28100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>14300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>19700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>10700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>11500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>10700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>16300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit  trainees  age  earnings\n",
       "0      1         1   28     17700\n",
       "1      2         1   34     10200\n",
       "2      3         1   29     14400\n",
       "3      4         1   25     20800\n",
       "4      5         1   29      6100\n",
       "5      6         1   23     28600\n",
       "6      7         1   33     21900\n",
       "7      8         1   27     28800\n",
       "8      9         1   31     20300\n",
       "9     10         1   26     28100\n",
       "10    11         1   25      9400\n",
       "11    12         1   27     14300\n",
       "12    13         1   29     12500\n",
       "13    14         1   24     19700\n",
       "14    15         1   25     10100\n",
       "15    16         1   43     10700\n",
       "16    17         1   28     11500\n",
       "17    18         1   27     10700\n",
       "18    19         1   28     16300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee = pd.read_csv(\"./data/trainees.csv\")\n",
    "trainee.query(\"trainees==1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et les non-stagiaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>trainees</th>\n",
       "      <th>age</th>\n",
       "      <th>earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>20900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>31000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>41100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>29800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>25500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>15500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>26600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>24200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>23300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>30200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>17800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>25900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit  trainees  age  earnings\n",
       "19    20         0   43     20900\n",
       "20    21         0   50     31000\n",
       "21    22         0   30     21000\n",
       "22    23         0   27      9300\n",
       "23    24         0   54     41100\n",
       "24    25         0   48     29800\n",
       "25    26         0   39     42000\n",
       "26    27         0   28      8800\n",
       "27    28         0   24     25500\n",
       "28    29         0   33     15500\n",
       "29    31         0   26       400\n",
       "30    32         0   31     26600\n",
       "31    33         0   26     16500\n",
       "32    34         0   34     24200\n",
       "33    35         0   25     23300\n",
       "34    36         0   24      9700\n",
       "35    37         0   29      6200\n",
       "36    38         0   35     30200\n",
       "37    39         0   32     17800\n",
       "38    40         0   23      9500\n",
       "39    41         0   32     25900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee.query(\"trainees==0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si je fais une simple comparaison des moyennes, nous constatons que les stagiaires gagnent moins d'argent que ceux qui n'ont pas suivi le programme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4297.49373433584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainee.query(\"trainees==1\")[\"earnings\"].mean() - trainee.query(\"trainees==0\")[\"earnings\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, si nous regardons le tableau ci-dessus, nous remarquons que les stagiaires sont beaucoup plus jeunes que les non-stagiaires, ce qui indique que l'âge est probablement un facteur de confusion. Utilisons le matching sur l'âge pour essayer de corriger cela. Nous prendrons l'unité 1 parmi les traités et l'apparierons avec l'unité 27, car les deux ont 28 ans. L'unité 2 sera appariée avec l'unité 34, l'unité 3 avec l'unité 37, l'unité 4 sera appariée avec l'unité 35... En ce qui concerne l'unité 5, nous devons trouver quelqu'un âgé de 29 ans parmi les non-traités, mais c'est l'unité 37, qui est déjà appariée. Cela ne pose pas de problème, car nous pouvons utiliser la même unité plusieurs fois. Si plusieurs unités sont compatibles, nous pouvons choisir au hasard parmi elles.\n",
    "\n",
    "Voici à quoi ressemble l'ensemble de données appariées pour les 7 premières unités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_t_1</th>\n",
       "      <th>trainees_t_1</th>\n",
       "      <th>age</th>\n",
       "      <th>earnings_t_1</th>\n",
       "      <th>unit_t_0</th>\n",
       "      <th>trainees_t_0</th>\n",
       "      <th>earnings_t_0</th>\n",
       "      <th>t1_minuts_t0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>17700</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8800</td>\n",
       "      <td>8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10200</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>24200</td>\n",
       "      <td>-14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>14400</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>20800</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>23300</td>\n",
       "      <td>-2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>6100</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>6200</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>28600</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>9500</td>\n",
       "      <td>19100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>21900</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>15500</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_t_1  trainees_t_1  age  earnings_t_1  unit_t_0  trainees_t_0  \\\n",
       "0         1             1   28         17700        27             0   \n",
       "1         2             1   34         10200        34             0   \n",
       "2         3             1   29         14400        37             0   \n",
       "3         4             1   25         20800        35             0   \n",
       "4         5             1   29          6100        37             0   \n",
       "5         6             1   23         28600        40             0   \n",
       "6         7             1   33         21900        29             0   \n",
       "\n",
       "   earnings_t_0  t1_minuts_t0  \n",
       "0          8800          8900  \n",
       "1         24200        -14000  \n",
       "2          6200          8200  \n",
       "3         23300         -2500  \n",
       "4          6200          -100  \n",
       "5          9500         19100  \n",
       "6         15500          6400  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dataset where no one has the same age\n",
    "unique_on_age = (trainee\n",
    "                 .query(\"trainees==0\")\n",
    "                 .drop_duplicates(\"age\"))\n",
    "\n",
    "matches = (trainee\n",
    "           .query(\"trainees==1\")\n",
    "           .merge(unique_on_age, on=\"age\", how=\"left\", suffixes=(\"_t_1\", \"_t_0\"))\n",
    "           .assign(t1_minuts_t0 = lambda d: d[\"earnings_t_1\"] - d[\"earnings_t_0\"]))\n",
    "\n",
    "matches.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquez comment la dernière colonne montre la différence de revenus entre l'unité traitée et son unité non traitée appariée. Si nous prenons la moyenne de cette dernière colonne, nous obtenons l'estimation de l'ATET tout en contrôlant l'âge. Remarquez comment l'estimation est maintenant très positive, comparée à celle précédente où nous avions utilisé une simple différence de moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2457.8947368421054"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[\"t1_minuts_t0\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais ceci était un exemple très artificiel, juste pour introduire le matching. En réalité, nous avons généralement plus d'une caractéristique et les unités ne correspondent pas parfaitement. Dans ce cas, nous devons définir une mesure de proximité pour comparer à quel point les unités sont proches les unes des autres. Une métrique courante pour cela est la norme euclidienne $||X_i - X_j||$. Cette différence, cependant, n'est pas invariante à l'échelle des caractéristiques. Cela signifie que des caractéristiques comme l'âge, qui prennent des valeurs en dizaines, seront beaucoup moins importantes lors du calcul de cette norme par rapport à des caractéristiques comme le revenu, qui prennent des valeurs de l'ordre de centaines. Pour cette raison, avant d'appliquer la norme, nous devons mettre les caractéristiques à l'échelle pour qu'elles soient à peu près sur la même échelle.\n",
    "\n",
    "Ayant défini une mesure de distance, nous pouvons maintenant définir le matching comme le plus proche voisin de cet échantillon que nous souhaitons apparier. En termes mathématiques, nous pouvons écrire l'estimateur de matching de la manière suivante :\n",
    "\n",
    "$$\n",
    "\\hat{ATE} = \\frac{1}{N} \\sum^N_{i=1} (2T_i - 1)\\big(Y_i - Y_{jm}(i)\\big)\n",
    "$$\n",
    "\n",
    "Où $Y_{jm}(i)$ est l'échantillon du groupe de traitement opposé qui est le plus similaire à $Y_i$. Nous faisons ce $2T_i - 1$ pour apparier dans les deux sens : traités avec les contrôles et contrôles avec les traités.\n",
    "\n",
    "Pour tester cet estimateur, considérons un exemple de médecine. Encore une fois, nous voulons trouver l'effet d'un médicament sur le nombre de jours jusqu'à la guérison. Malheureusement, cet effet est confondu par la gravité, le sexe et l'âge. Nous avons des raisons de croire que les patients ayant des conditions plus graves ont une probabilité plus élevée de recevoir le médicament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.049134</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.580323</td>\n",
       "      <td>0.899784</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.127491</td>\n",
       "      <td>0.486349</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.375033</td>\n",
       "      <td>0.323091</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25.091717</td>\n",
       "      <td>0.209006</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex        age  severity  medication  recovery\n",
       "0    0  35.049134  0.887658           1        31\n",
       "1    1  41.580323  0.899784           1        49\n",
       "2    1  28.127491  0.486349           0        38\n",
       "3    1  36.375033  0.323091           0        35\n",
       "4    0  25.091717  0.209006           0        15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med = pd.read_csv(\"./data/medicine_impact_recovery.csv\")\n",
    "med.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous examinons une simple différence de moyennes, $E[Y|T=1]-E[Y|T=0]$, nous constatons que le traitement prend, en moyenne, 16,9 jours de plus pour se rétablir que les non-traités. Cela est probablement dû à des facteurs de confusion, car nous ne nous attendons pas à ce que le médicament nuise au patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.895799546498726"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med.query(\"medication==1\")[\"recovery\"].mean() - med.query(\"medication==0\")[\"recovery\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour corriger ce biais, nous allons contrôler les variables X en utilisant le matching. Tout d'abord, nous devons nous rappeler de mettre nos caractéristiques à l'échelle, sinon des caractéristiques comme l'âge auront plus d'importance que des caractéristiques comme la gravité lorsque nous calculerons la distance entre les points. Pour ce faire, nous pouvons standardiser les caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>0.280787</td>\n",
       "      <td>1.459800</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>1.502164</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>-0.338749</td>\n",
       "      <td>0.057796</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>0.399465</td>\n",
       "      <td>-0.512557</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>-0.610473</td>\n",
       "      <td>-0.911125</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex       age  severity  medication  recovery\n",
       "0 -0.996980  0.280787  1.459800           1        31\n",
       "1  1.002979  0.865375  1.502164           1        49\n",
       "2  1.002979 -0.338749  0.057796           0        38\n",
       "3  1.002979  0.399465 -0.512557           0        35\n",
       "4 -0.996980 -0.610473 -0.911125           0        15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale features\n",
    "X = [\"severity\", \"age\", \"sex\"]\n",
    "y = \"recovery\"\n",
    "\n",
    "med = med.assign(**{f: (med[f] - med[f].mean())/med[f].std() for f in X})\n",
    "med.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, passons au matching lui-même. Au lieu de coder une fonction de matching, nous utiliserons l'algorithme des K plus proches voisins de [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html). Cet algorithme fait des prédictions en trouvant le point de données le plus proche dans un ensemble d'estimation ou d'entraînement.\n",
    "\n",
    "Pour le matching, nous aurons besoin de 2 de ces modèles. L'un, `mt0`, stockera les points non traités et trouvera des correspondances parmi les non traités lorsqu'on le lui demandera. L'autre, `mt1`, stockera les points traités et trouvera des correspondances parmi les traités lorsqu'on le lui demandera. Après cette étape de fitting, nous pourrons utiliser ces modèles KNN pour faire des prédictions, qui seront nos correspondances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>0.280787</td>\n",
       "      <td>1.459800</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>1.502164</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>1.495134</td>\n",
       "      <td>1.268540</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>-0.106534</td>\n",
       "      <td>0.545911</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>1.428732</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex       age  severity  medication  recovery  match\n",
       "0  -0.996980  0.280787  1.459800           1        31   39.0\n",
       "1   1.002979  0.865375  1.502164           1        49   52.0\n",
       "7  -0.996980  1.495134  1.268540           1        38   46.0\n",
       "10  1.002979 -0.106534  0.545911           1        34   45.0\n",
       "16 -0.996980  0.043034  1.428732           1        30   39.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "treated = med.query(\"medication==1\")\n",
    "untreated = med.query(\"medication==0\")\n",
    "\n",
    "mt0 = KNeighborsRegressor(n_neighbors=1).fit(untreated[X], untreated[y])\n",
    "mt1 = KNeighborsRegressor(n_neighbors=1).fit(treated[X], treated[y])\n",
    "\n",
    "predicted = pd.concat([\n",
    "    # find matches for the treated looking at the untreated knn model\n",
    "    treated.assign(match=mt0.predict(treated[X])),\n",
    "    \n",
    "    # find matches for the untreated looking at the treated knn model\n",
    "    untreated.assign(match=mt1.predict(untreated[X]))\n",
    "])\n",
    "\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les observations appariées, nous pouvons maintenant appliquer la formule de l'estimateur de matching\n",
    "\n",
    "$\n",
    "\\hat{ATE} = \\frac{1}{N} \\sum^N_{i=1} (2T_i - 1)\\big(Y_i - Y_{jm}(i)\\big)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9954"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((2*predicted[\"medication\"] - 1)*(predicted[\"recovery\"] - predicted[\"match\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant ce type d'appariement, nous pouvons voir que l'effet du médicament n'est plus positif. Cela signifie qu'en contrôlant pour X, le médicament réduit le temps de récupération d'environ un jour, en moyenne. C'est déjà une amélioration considérable par rapport à l'estimation biaisée qui prédisait une augmentation de 16,9 jours du temps de récupération.\n",
    "\n",
    "Cependant, nous pouvons encore faire mieux.\n",
    "\n",
    "## Biais de Matching\n",
    "\n",
    "Il s'avère que l'estimateur de matching tel que nous l'avons conçu ci-dessus est biaisé. Pour comprendre cela, considérons l'estimateur ATET (Average Treatment Effect on the Treated), au lieu de l'ATE, simplement parce qu'il est plus simple à écrire. L'intuition s'appliquera également à l'ATE.\n",
    "\n",
    "$$\n",
    "\\hat{ATET} = \\frac{1}{N_1}\\sum (Y_i - Y_j(i))\n",
    "$$\n",
    "\n",
    "où $N_1$ est le nombre d'individus traités et $Y_j(i)$ est la correspondance non traitée de l'unité traitée i. Pour vérifier le biais, ce que nous faisons, c'est espérer pouvoir appliquer le Théorème Central Limite afin que ce qui suit converge vers une distribution normale avec une moyenne de zéro.\n",
    "\n",
    "$$\n",
    "\\sqrt{N_1}(\\hat{ATET} - ATET)\n",
    "$$\n",
    "\n",
    "Cependant, cela n'arrive pas toujours. Si nous définissons la moyenne des résultats pour les non-traités en fonction de X, $\\mu_0(x)=E[Y|X=x, T=0]$, nous aurons que (entre parenthèses, j'ai omis la démonstration car elle dépasse un peu le sujet ici).\n",
    "\n",
    "$$\n",
    "E[\\sqrt{N_1}(\\hat{ATET} - ATET)] = E[\\sqrt{N_1}(\\mu_0(X_i) - \\mu_0(X_j(i)))]\n",
    "$$\n",
    "\n",
    "Maintenant, $\\mu_0(X_i) - \\mu_0(X_j(i))$ n'est pas si simple à comprendre, alors examinons-le plus attentivement. $\\mu_0(X_i)$ est la valeur de Y d'une unité traitée $i$ si elle n'avait pas été traitée. C'est donc le résultat contrefactuel $Y_0$ pour l'unité i. $\\mu_0(X_j(i))$ est le résultat de l'unité non traitée $j$ qui est l'appariement de l'unité $i$. C'est donc également le $Y_0$, mais pour l'unité $j$ maintenant. Cette fois-ci, c'est un résultat factuel, car $j$ est dans le groupe non traité. Comme $j$ et $i$ sont seulement similaires, mais pas identiques, cela ne sera probablement pas nul. En d'autres termes, $X_i \\approx X_j$. Donc, $Y_{0i} \\approx Y_{0j}$.\n",
    "\n",
    "À mesure que nous augmentons la taille de l'échantillon, il y aura plus d'unités à apparier, donc la différence entre l'unité $i$ et son appariement $j$ diminuera également. Mais cette différence converge lentement vers zéro. En conséquence, $E[\\sqrt{N_1}(\\mu_0(X_i) - \\mu_0(X_j(i)))]$ peut ne pas converger vers zéro, car le $\\sqrt{N_1}$ croît plus rapidement que $(\\mu_0(X_i) - \\mu_0(X_j(i)))$ ne diminue.\n",
    "\n",
    "Le biais apparaît lorsque les écarts de matching sont importants. Heureusement, nous savons comment le corriger. Chaque observation contribue $(\\mu_0(X_i) - \\mu_0(X_j(i)))$ au biais, donc tout ce que nous avons à faire est de soustraire cette quantité de chaque comparaison de matching dans notre estimateur. Pour ce faire, nous pouvons remplacer $\\mu_0(X_j(i))$ par une sorte d'estimation de cette quantité $\\hat{\\mu_0}(X_j(i))$, qui peut être obtenue avec des modèles comme la régression linéaire. Cela met à jour l'estimateur ATET avec l'équation suivante :\n",
    "\n",
    "$$\n",
    "\\hat{ATET} = \\frac{1}{N_1}\\sum \\big((Y_i - Y_{j(i)}) - (\\hat{\\mu_0}(X_i) - \\hat{\\mu_0}(X_{j(i)}))\\big)\n",
    "$$\n",
    "\n",
    "où $\\hat{\\mu_0}(x)$ est une estimation de $E[Y|X, T=0]$, comme une régression linéaire ajustée uniquement sur l'échantillon non traité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>severity</th>\n",
       "      <th>medication</th>\n",
       "      <th>recovery</th>\n",
       "      <th>match</th>\n",
       "      <th>bias_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>0.280787</td>\n",
       "      <td>1.459800</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.404034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>1.502164</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.915348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>1.495134</td>\n",
       "      <td>1.268540</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.871428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>-0.106534</td>\n",
       "      <td>0.545911</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-0.496970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.996980</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>1.428732</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.610159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex       age  severity  medication  recovery  match  bias_correct\n",
       "0  -0.996980  0.280787  1.459800           1        31   39.0      4.404034\n",
       "1   1.002979  0.865375  1.502164           1        49   52.0     12.915348\n",
       "7  -0.996980  1.495134  1.268540           1        38   46.0      1.871428\n",
       "10  1.002979 -0.106534  0.545911           1        34   45.0     -0.496970\n",
       "16 -0.996980  0.043034  1.428732           1        30   39.0      2.610159"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# fit the linear regression model to estimate mu_0(x)\n",
    "ols0 = LinearRegression().fit(untreated[X], untreated[y])\n",
    "ols1 = LinearRegression().fit(treated[X], treated[y])\n",
    "\n",
    "# find the units that match to the treated\n",
    "treated_match_index = mt0.kneighbors(treated[X], n_neighbors=1)[1].ravel()\n",
    "\n",
    "# find the units that match to the untreatd\n",
    "untreated_match_index = mt1.kneighbors(untreated[X], n_neighbors=1)[1].ravel()\n",
    "\n",
    "predicted = pd.concat([\n",
    "    (treated\n",
    "     # find the Y match on the other group\n",
    "     .assign(match=mt0.predict(treated[X])) \n",
    "     \n",
    "     # build the bias correction term\n",
    "     .assign(bias_correct=ols0.predict(treated[X]) - ols0.predict(untreated.iloc[treated_match_index][X]))),\n",
    "    (untreated\n",
    "     .assign(match=mt1.predict(untreated[X]))\n",
    "     .assign(bias_correct=ols1.predict(untreated[X]) - ols1.predict(treated.iloc[untreated_match_index][X])))\n",
    "])\n",
    "\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une question immédiate qui se pose est : cela ne va-t-il pas à l'encontre de l'objectif du matching ? Si je dois de toute façon effectuer une régression linéaire, pourquoi ne pas utiliser uniquement cela, au lieu de ce modèle compliqué ? C'est un point valable, donc je devrais prendre un moment pour y répondre.\n",
    "\n",
    "![img](./data/img/matching/ubiquitous-ols.png)\n",
    "\n",
    "Tout d'abord, cette régression linéaire que nous ajustons ne fait pas d'extrapolation sur la dimension du traitement pour obtenir l'effet du traitement. Son objectif est plutôt de corriger le biais. La régression linéaire ici est locale, dans le sens où elle ne cherche pas à voir comment les traités se comporteraient s'ils ressemblaient aux non-traités. Elle ne fait aucune de ces extrapolations. Cela est laissé à la partie matching. L'essentiel de l'estimateur reste la composante de matching. Ce que je veux dire ici, c'est que la régression linéaire (OLS) est secondaire dans cet estimateur.\n",
    "\n",
    "Le deuxième point est que le matching est un estimateur non paramétrique. Il ne suppose pas de linéarité ou de modèle paramétrique quelconque. En tant que tel, il est plus flexible que la régression linéaire et peut fonctionner dans des situations où la régression linéaire ne le pourrait pas, notamment lorsque la non-linéarité est très forte.\n",
    "\n",
    "Cela signifie-t-il que vous devriez utiliser uniquement le matching ? Eh bien, c'est une question difficile. Alberto Abadie affirme que oui, vous devriez. C'est plus flexible et, une fois que vous avez le code, tout aussi simple à exécuter. Je ne suis pas entièrement convaincu par cela. Par exemple, Abadie a passé beaucoup de temps à étudier et développer l'estimateur (oui, il est l'un des scientifiques qui ont contribué à faire du matching ce qu'il est), il est donc évidemment personnellement investi dans la méthode. Deuxièmement, il y a quelque chose dans la simplicité de la régression linéaire que vous ne voyez pas dans le matching. Les mathématiques de la dérivée partielle consistant à \"garder tout le reste constant\" sont beaucoup plus faciles à comprendre avec la régression linéaire qu'avec le matching. Mais c'est juste ma préférence. Pour être honnête, il n'y a pas de réponse claire à cette question. Quoi qu'il en soit, revenons à notre exemple.\n",
    "\n",
    "Avec la formule de correction du biais, j'obtiens l'estimation suivante de l'ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.36266090614141"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((2*predicted[\"medication\"] - 1)*((predicted[\"recovery\"] - predicted[\"match\"])-predicted[\"bias_correct\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien sûr, nous devons également placer un intervalle de confiance autour de cette mesure, mais assez de théorie mathématique pour l’instant. En pratique, nous pouvons simplement utiliser le code de quelqu’un d’autre et importer un estimateur de matching. En voici un de la bibliothèque  [causalinference](https://github.com/laurencium/causalinference). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treatment Effect Estimates: Matching\n",
      "\n",
      "                     Est.       S.e.          z      P>|z|      [95% Conf. int.]\n",
      "--------------------------------------------------------------------------------\n",
      "           ATE     -7.709      0.609    -12.649      0.000     -8.903     -6.514\n",
      "           ATC     -6.665      0.246    -27.047      0.000     -7.148     -6.182\n",
      "           ATT     -9.679      1.693     -5.717      0.000    -12.997     -6.361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from causalinference import CausalModel\n",
    "\n",
    "cm = CausalModel(\n",
    "    Y=med[\"recovery\"].values, \n",
    "    D=med[\"medication\"].values, \n",
    "    X=med[[\"severity\", \"age\", \"sex\"]].values\n",
    ")\n",
    "\n",
    "cm.est_via_matching(matches=1, bias_adj=True)\n",
    "\n",
    "print(cm.estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous pouvons dire avec confiance que notre médicament réduit effectivement le temps passé à l'hôpital. L'estimation ATE est juste un peu plus basse que la mienne, en raison de la différence dans le dénouement des égalités des correspondances de l'implémentation knn de sklearn et du package Python causalinference.\n",
    "\n",
    "Avant de clore ce sujet, je voulais juste aborder un peu plus la cause du biais dans le matching. Nous avons vu que le matching est biaisé lorsque l'unité et sa correspondance ne sont pas si similaires. Mais qu'est-ce qui les rend si différents ?\n",
    "\n",
    "## Le Fléau de la Dimensionalité\n",
    "\n",
    "Il s'avère que la réponse est assez simple et intuitive. Il est facile de trouver des personnes qui correspondent sur quelques caractéristiques, comme le sexe. Mais si nous ajoutons plus de caractéristiques, comme l'âge, le revenu, la ville de naissance, etc., il devient de plus en plus difficile de trouver des correspondances. En termes plus généraux, plus nous avons de caractéristiques, plus la distance entre les unités et leurs correspondances sera élevée.\n",
    "\n",
    "Cela ne nuit pas seulement à l'estimateur de matching. Cela se rattache à l'estimateur de sous-classification que nous avons vu plus tôt. Au début, dans cet exemple de médicament inventé avec des hommes et des femmes, il était assez facile de construire l'estimateur de sous-classification. C'était parce que nous n'avions que 2 cellules : homme et femme. Mais que se passerait-il si nous en avions plus ? Supposons que nous ayons 2 caractéristiques continues comme l'âge et le revenu et que nous réussissions à les discrétiser en 5 catégories chacune. Cela nous donnerait 25 cellules, ou $5^2$. Et si nous avions 10 covariables avec 3 catégories chacune ? Cela ne semble pas beaucoup, n'est-ce pas ? Eh bien, cela nous donnerait 59049 cellules, ou $3^{10}$. Il est facile de voir comment cela peut rapidement devenir disproportionné. C'est un phénomène omniprésent dans toute la science des données, appelé **Le Fléau de la Dimensionalité** !!!\n",
    "\n",
    "![img](./data/img/curse-of-dimensionality.jpg)\n",
    "Source de l'image : https://deepai.org/machine-learning-glossary-and-terms/curse-of-dimensionality\n",
    "\n",
    "Malgré son nom effrayant et prétentieux, cela signifie simplement que le nombre de points de données nécessaires pour remplir un espace de caractéristiques augmente de façon exponentielle avec le nombre de caractéristiques, ou dimensions. Donc, s'il faut X points de données pour remplir l'espace de, disons, 3 espaces de caractéristiques, il en faut exponentiellement plus pour remplir l'espace de 4 caractéristiques.\n",
    "\n",
    "Dans le contexte de l'estimateur de sous-classification, le fléau de la dimensionalité signifie qu'il souffrira si nous avons beaucoup de caractéristiques. Beaucoup de caractéristiques impliquent de multiples cellules en X. S'il y a plusieurs cellules, certaines d'entre elles auront très peu de données. Certaines pourraient même avoir seulement des traitements ou seulement des contrôles, il ne sera donc pas possible d'estimer l'ATE là-bas, ce qui casserait notre estimateur. Dans le contexte du matching, cela signifie que l'espace des caractéristiques sera très clairsemé et que les unités seront très éloignées les unes des autres. Cela augmentera la distance entre les correspondances et causera des problèmes de biais.\n",
    "\n",
    "En ce qui concerne la régression linéaire, elle gère en fait très bien ce problème. Ce qu'elle fait, c'est projeter toutes les caractéristiques X sur une seule, la dimension Y. Elle compare ensuite le traitement et le contrôle sur cette projection. Donc, d'une certaine manière, la régression linéaire effectue une sorte de réduction de dimension pour estimer l'ATE. C'est assez élégant.\n",
    "\n",
    "La plupart des modèles causaux ont également une méthode pour traiter le fléau de la dimensionalité. Je ne vais pas me répéter, mais c'est quelque chose dont vous devriez vous souvenir lorsque vous les examinez. Par exemple, lorsque nous traitons des scores de propension dans la section suivante, essayez de voir comment ils résolvent ce problème.\n",
    "\n",
    "## Idées Clés\n",
    "\n",
    "Nous avons commencé cette section en comprenant ce que fait la régression linéaire et comment elle peut nous aider à identifier les relations causales. À savoir, nous avons compris que la régression peut être vue comme la partition du jeu de données en cellules, le calcul de l'ATE dans chaque cellule, puis la combinaison de l'ATE des cellules en un seul ATE pour l'ensemble du jeu de données.\n",
    "\n",
    "À partir de là, nous avons dérivé un estimateur d'inférence causale très général avec sous-classification. Nous avons vu comment cet estimateur n'est pas très utile en pratique, mais il nous a donné des idées intéressantes sur la manière de résoudre le problème de l'estimation de l'inférence causale. Cela nous a donné l'opportunité de parler de l'estimateur de matching.\n",
    "\n",
    "Le matching contrôle les variables confondantes en regardant chaque unité traitée et en trouvant une paire non traitée qui lui est très similaire et de même pour les unités non traitées. Nous avons vu comment mettre en œuvre cette méthode en utilisant l'algorithme KNN et aussi comment la débiasser en utilisant la régression. Enfin, nous avons discuté de la différence entre le matching et la régression linéaire. Nous avons vu comment le matching est un estimateur non paramétrique qui ne repose pas sur la linéarité comme le fait la régression linéaire.\n",
    "\n",
    "Enfin, nous avons abordé le problème des jeux de données à haute dimension et nous avons vu comment les méthodes d'inférence causale peuvent en souffrir.\n",
    "\n",
    "## Références\n",
    "\n",
    "J'aime penser à ce livre entier comme un hommage à Joshua Angrist, Alberto Abadie et Christopher Walters pour leur incroyable cours d'économétrie. La plupart des idées ici sont tirées de leurs cours à l'American Economic Association. Les regarder est ce qui me maintient sain d'esprit pendant cette année difficile de 2020.\n",
    "* [Cross-Section Econometrics](https://www.aeaweb.org/conference/cont-ed/2017-webcasts)\n",
    "* [Mastering Mostly Harmless Econometrics](https://www.aeaweb.org/conference/cont-ed/2020-webcasts)\n",
    "\n",
    "Je tiens également à référencer les livres incroyables d'Angrist. Ils m'ont montré que l'économétrie, ou 'Metrics' comme ils l'appellent, n'est pas seulement extrêmement utile mais aussi profondément amusante.\n",
    "\n",
    "* [Mostly Harmless Econometrics](https://www.mostlyharmlesseconometrics.com/)\n",
    "* [Mastering 'Metrics](https://www.masteringmetrics.com/)\n",
    "\n",
    "Ma dernière référence est le livre de Miguel Hernan et Jamie Robins. Il a été mon compagnon fidèle dans les questions causales les plus épineuses que j'ai dû résoudre.\n",
    "\n",
    "* [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)\n",
    "\n",
    "Les données utilisées ici proviennent d'une étude de Alpert, William T., Kenneth A. Couch, et Oskar R. Harmon. 2016. [\"A Randomized Assessment of Online Learning\"](https://www.aeaweb.org/articles?id=10.1257/aer.p20161057). American Economic Review, 106 (5): 378-82.\n",
    "\n",
    "![img](./data/img/poetry.png)\n",
    "\n",
    "## Contribuer\n",
    "\n",
    "*L'Inférence Causale pour les Courageux et les Vrais* est un matériel open-source sur l'inférence causale, la statistique de la science. Son objectif est d'être accessible monétairement et intellectuellement. Il utilise uniquement des logiciels gratuits basés sur Python.\n",
    "Si vous avez trouvé ce livre précieux et souhaitez le soutenir, veuillez vous rendre sur [Patreon](https://www.patreon.com/causal_inference_for_the_brave_and_true). Si vous n'êtes pas prêt à contribuer financièrement, vous pouvez également aider en corrigeant les fautes de frappe, en suggérant des modifications ou en donnant votre avis sur les passages que vous n'avez pas compris. Rendez-vous sur le repo du livre et [ouvrez une issue](https://github.com/matheusfacure/python-causality-handbook/issues). Enfin, si vous avez aimé ce contenu, veuillez le partager avec d'autres personnes qui pourraient le trouver utile et lui donner une [étoile sur GitHub](https://github.com/matheusfacure/python-causality-handbook/stargazers)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
