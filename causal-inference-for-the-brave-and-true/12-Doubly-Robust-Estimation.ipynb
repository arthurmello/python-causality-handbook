{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Estimation Doublement Robuste\n",
    "\n",
    "## Ne Mettez Pas Tous Vos Œufs dans le Même Panier\n",
    "\n",
    "Nous avons appris à utiliser la régression linéaire et la pondération par score de propension pour estimer $E[Y|T=1] - E[Y|T=0] | X$. Mais laquelle de ces méthodes devrions-nous utiliser, et quand ? En cas de doute, utilisez simplement les deux ! L'estimation doublement robuste est une méthode qui combine le score de propension et la régression linéaire de manière à ne pas avoir à se fier entièrement à l'une ou l'autre méthode.\n",
    "\n",
    "Pour comprendre comment cela fonctionne, considérons l'expérience sur le mindset. Il s'agit d'une étude randomisée menée dans des lycées publics aux États-Unis, visant à évaluer l'impact du mindset de croissance. Les élèves reçoivent un séminaire de la part de l'école pour leur inculquer un mindset de croissance. Ensuite, on les suit pendant leurs années de collège pour mesurer leurs performances académiques. Cette mesure a été compilée en un score de réussite et standardisée. Les données réelles de cette étude ne sont pas disponibles publiquement afin de préserver la confidentialité des élèves. Cependant, nous disposons d'un ensemble de données simulées avec les mêmes propriétés statistiques, fourni par [Athey et Wager](https://arxiv.org/pdf/1902.07409.pdf), que nous allons utiliser à la place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.498438Z",
     "start_time": "2023-03-14T11:05:46.659452Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "pd.set_option(\"display.max_columns\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.535134Z",
     "start_time": "2023-03-14T11:05:50.500165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schoolid</th>\n",
       "      <th>intervention</th>\n",
       "      <th>achievement_score</th>\n",
       "      <th>...</th>\n",
       "      <th>school_ethnic_minority</th>\n",
       "      <th>school_poverty</th>\n",
       "      <th>school_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515202</td>\n",
       "      <td>-0.169849</td>\n",
       "      <td>0.173954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.987277</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.152340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875012</td>\n",
       "      <td>-0.724801</td>\n",
       "      <td>0.761781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315755</td>\n",
       "      <td>0.054586</td>\n",
       "      <td>1.862187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.360920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033161</td>\n",
       "      <td>-0.982274</td>\n",
       "      <td>1.591641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      schoolid  intervention  achievement_score  ...  school_ethnic_minority  \\\n",
       "259         73             1           1.480828  ...               -0.515202   \n",
       "3435        76             0          -0.987277  ...               -1.310927   \n",
       "9963         4             0          -0.152340  ...                0.875012   \n",
       "4488        67             0           0.358336  ...                0.315755   \n",
       "2637        16             1           1.360920  ...               -0.033161   \n",
       "\n",
       "      school_poverty  school_size  \n",
       "259        -0.169849     0.173954  \n",
       "3435        0.224077    -0.426757  \n",
       "9963       -0.724801     0.761781  \n",
       "4488        0.054586     1.862187  \n",
       "2637       -0.982274     1.591641  \n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/learning_mindset.csv\")\n",
    "data.sample(5, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que l'étude ait été randomisée, il ne semble pas que ces données soient exemptes de facteurs de confusion. Une des raisons possibles à cela est que la variable de traitement est mesurée par la participation des élèves au séminaire. Ainsi, bien que l'opportunité de participer ait été aléatoire, la participation elle-même ne l'est pas. Nous sommes ici confrontés à un cas de non-conformité. Une preuve de cela est que les attentes de réussite des élèves sont corrélées avec leur participation au séminaire. Les élèves qui se déclarent avoir des attentes élevées sont plus susceptibles d'avoir rejoint le séminaire sur le mindset de croissance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.546638Z",
     "start_time": "2023-03-14T11:05:50.538742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success_expect\n",
       "1    0.271739\n",
       "2    0.265957\n",
       "3    0.294118\n",
       "4    0.271617\n",
       "5    0.311070\n",
       "6    0.354287\n",
       "7    0.362319\n",
       "Name: intervention, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"success_expect\")[\"intervention\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous le savons maintenant, nous pourrions ajuster cela en utilisant une régression linéaire ou en estimant un modèle de score de propension avec une régression logistique. Cependant, avant de faire cela, nous devons convertir les variables catégorielles en variables dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.559709Z",
     "start_time": "2023-03-14T11:05:50.548969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10391, 32)\n"
     ]
    }
   ],
   "source": [
    "categ = [\"ethnicity\", \"gender\", \"school_urbanicity\"]\n",
    "cont = [\"school_mindset\", \"school_achievement\", \"school_ethnic_minority\", \"school_poverty\", \"school_size\"]\n",
    "\n",
    "data_with_categ = pd.concat([\n",
    "    data.drop(columns=categ), # dataset without the categorical features\n",
    "    pd.get_dummies(data[categ], columns=categ, drop_first=False) # categorical features converted to dummies\n",
    "], axis=1)\n",
    "\n",
    "print(data_with_categ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes maintenant prêts à comprendre comment fonctionne l'estimation doublement robuste.\n",
    "\n",
    "## Estimation Doublement Robuste (*Doubly Robust*)\n",
    "\n",
    "![img](./data/img/doubly-robust/double.png)\n",
    "\n",
    "Au lieu de dériver l'estimateur, je vais d'abord vous le montrer, puis expliquer pourquoi il est si impressionnant.\n",
    "\n",
    "$$\n",
    "\\hat{ATE} = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_i(Y_i - \\hat{\\mu_1}(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg) - \\frac{1}{N}\\sum \\bigg( \\dfrac{(1-T_i)(Y_i - \\hat{\\mu_0}(X_i))}{1-\\hat{P}(X_i)} + \\hat{\\mu_0}(X_i) \\bigg)\n",
    "$$\n",
    "\n",
    "où $\\hat{P}(x)$ est une estimation du score de propension (en utilisant par exemple une régression logistique), $\\hat{\\mu_1}(x)$ est une estimation de $E[Y|X, T=1]$ (en utilisant par exemple une régression linéaire), et $\\hat{\\mu_0}(x)$ est une estimation de $E[Y|X, T=0]$. Comme vous l'avez peut-être déjà deviné, la première partie de l'estimateur doublement robuste estime $E[Y_1]$ et la deuxième partie estime $E[Y_0]$. Examinons la première partie, car toute l'intuition s'appliquera également à la deuxième partie par analogie.\n",
    "\n",
    "Je sais que cette formule peut sembler intimidante au premier abord (mais ne vous inquiétez pas, vous verrez que c'est en réalité très simple). Je vais d'abord montrer comment coder cet estimateur. J'ai le sentiment que certaines personnes sont moins effrayées par du code que par des formules. Voyons comment cet estimateur fonctionne en pratique, d'accord ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.566875Z",
     "start_time": "2023-03-14T11:05:50.562600Z"
    }
   },
   "outputs": [],
   "source": [
    "def doubly_robust(df, X, T, Y):\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(df[X], df[T]).predict_proba(df[X])[:, 1]\n",
    "    mu0 = LinearRegression().fit(df.query(f\"{T}==0\")[X], df.query(f\"{T}==0\")[Y]).predict(df[X])\n",
    "    mu1 = LinearRegression().fit(df.query(f\"{T}==1\")[X], df.query(f\"{T}==1\")[Y]).predict(df[X])\n",
    "    return (\n",
    "        np.mean(df[T]*(df[Y] - mu1)/ps + mu1) -\n",
    "        np.mean((1-df[T])*(df[Y] - mu0)/(1-ps) + mu0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.753508Z",
     "start_time": "2023-03-14T11:05:50.568291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38822121767832457"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 'intervention'\n",
    "Y = 'achievement_score'\n",
    "X = data_with_categ.columns.drop(['schoolid', T, Y])\n",
    "\n",
    "doubly_robust(data_with_categ, X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'estimateur doublement robuste indique que nous devrions nous attendre à ce que les individus ayant assisté au séminaire sur le mindset soient 0,388 écart-type au-dessus de leurs homologues non traités en termes de réussite. Une fois de plus, nous pouvons utiliser le bootstrap pour construire des intervalles de confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.493875Z",
     "start_time": "2023-03-14T11:05:50.757649Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed # for parallel processing\n",
    "\n",
    "np.random.seed(88)\n",
    "# run 1000 bootstrap samples\n",
    "bootstrap_sample = 1000\n",
    "ates = Parallel(n_jobs=4)(delayed(doubly_robust)(data_with_categ.sample(frac=1, replace=True), X, T, Y)\n",
    "                          for _ in range(bootstrap_sample))\n",
    "ates = np.array(ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.500840Z",
     "start_time": "2023-03-14T11:06:30.496065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE 95% CI: (0.35364752721776144, 0.41978441342477585)\n"
     ]
    }
   ],
   "source": [
    "print(f\"ATE 95% CI:\", (np.percentile(ates, 2.5), np.percentile(ates, 97.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.625413Z",
     "start_time": "2023-03-14T11:06:30.502013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ates, kde=False)\n",
    "plt.vlines(np.percentile(ates, 2.5), 0, 20, linestyles=\"dotted\")\n",
    "plt.vlines(np.percentile(ates, 97.5), 0, 20, linestyles=\"dotted\", label=\"95% CI\")\n",
    "plt.title(\"ATE Bootstrap Distribution\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons un aperçu de l'estimateur doublement robuste, examinons pourquoi il est si performant. Il est appelé \"doublement robuste\" parce qu'il ne nécessite qu'un seul des modèles, $\\hat{P}(x)$ ou $\\hat{\\mu}(x)$, pour être correctement spécifié. Pour comprendre cela, prenons la première partie qui estime $E[Y_1]$ et examinons-la attentivement.\n",
    "\n",
    "$$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_i(Y_i - \\hat{\\mu_1}(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$$\n",
    "\n",
    "Supposons que $\\hat{\\mu_1}(x)$ soit correct. Si le modèle de score de propension est erroné, nous n'avons pas à nous en inquiéter. En effet, si $\\hat{\\mu_1}(x)$ est correct, alors $E[T_i(Y_i - \\hat{\\mu_1}(X_i))]=0$. Cela est dû au fait que la multiplication par $T_i$ sélectionne uniquement les traités, et le résidu de $\\hat{\\mu_1}$ sur les traités a, par définition, une moyenne de zéro. Cela fait que l'expression se réduit à $\\hat{\\mu_1}(X_i)$, qui estime correctement $E[Y_1]$ par hypothèse. Vous voyez donc que si $\\hat{\\mu_1}(X_i)$ est correct, il élimine la pertinence du modèle de score de propension. Nous pouvons appliquer le même raisonnement pour comprendre l'estimateur de $E[Y_0]$.\n",
    "\n",
    "Mais ne me croyez pas sur parole, laissez le code vous montrer la voie ! Dans l'estimateur suivant, j'ai remplacé la régression logistique qui estime le score de propension par une variable aléatoire uniforme allant de 0,1 à 0,9 (je ne veux pas que des poids très faibles fassent exploser la variance du score de propension). Puisque cela est aléatoire, il n'y a aucune chance que ce soit un bon modèle de score de propension, mais nous verrons que l'estimateur doublement robuste parvient tout de même à produire une estimation très proche de celle obtenue lorsque le score de propension était estimé avec la régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.631039Z",
     "start_time": "2023-03-14T11:06:30.626680Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "def doubly_robust_wrong_ps(df, X, T, Y):\n",
    "    # wrong PS model\n",
    "    np.random.seed(654)\n",
    "    ps = np.random.uniform(0.1, 0.9, df.shape[0])\n",
    "    mu0 = LinearRegression().fit(df.query(f\"{T}==0\")[X], df.query(f\"{T}==0\")[Y]).predict(df[X])\n",
    "    mu1 = LinearRegression().fit(df.query(f\"{T}==1\")[X], df.query(f\"{T}==1\")[Y]).predict(df[X])\n",
    "    return (\n",
    "        np.mean(df[T]*(df[Y] - mu1)/ps + mu1) -\n",
    "        np.mean((1-df[T])*(df[Y] - mu0)/(1-ps) + mu0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.693635Z",
     "start_time": "2023-03-14T11:06:30.632597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3797369830995927"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubly_robust_wrong_ps(data_with_categ, X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous utilisons le bootstrap, nous pouvons constater que la variance est légèrement plus élevée que lorsque le score de propension était estimé par une régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:42.860551Z",
     "start_time": "2023-03-14T11:06:30.695579Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "parallel_fn = delayed(doubly_robust_wrong_ps)\n",
    "wrong_ps = Parallel(n_jobs=4)(parallel_fn(data_with_categ.sample(frac=1, replace=True), X, T, Y)\n",
    "                              for _ in range(bootstrap_sample))\n",
    "wrong_ps = np.array(wrong_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:42.865351Z",
     "start_time": "2023-03-14T11:06:42.861924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ATE 95% CI: (0.35364752721776144, 0.41978441342477585)\n",
      "Wrong PS ATE 95% CI: (0.33806443306747086, 0.4335673822553228)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original ATE 95% CI:\", (np.percentile(ates, 2.5), np.percentile(ates, 97.5)))\n",
    "\n",
    "print(f\"Wrong PS ATE 95% CI:\", (np.percentile(wrong_ps, 2.5), np.percentile(wrong_ps, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, altérer le score de propension produit des ATE légèrement différents, mais pas de manière significative. Cela couvre le cas où le modèle de propension est incorrect, mais le modèle de résultat est correct. Qu'en est-il de l'autre situation ? Prenons à nouveau un bon coup d'œil à la première partie de l'estimateur, mais réarrangeons certains termes :\n",
    "\n",
    "$$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_i(Y_i - \\hat{\\mu_1}(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_iY_i}{\\hat{P}(X_i)} - \\dfrac{T_i\\hat{\\mu_1}(X_i)}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_iY_i}{\\hat{P}(X_i)} - \\bigg(\\dfrac{T_i}{\\hat{P}(X_i)} - 1\\bigg) \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_iY_i}{\\hat{P}(X_i)} - \\bigg(\\dfrac{T_i - \\hat{P}(X_i)}{\\hat{P}(X_i)}\\bigg) \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$$\n",
    "\n",
    "Maintenant, supposons que le score de propension $\\hat{P}(X_i)$ soit correctement spécifié. Dans ce cas, $E[T_i - \\hat{P}(X_i)]=0$, ce qui annule la partie dépendante de $\\hat{\\mu_1}(X_i)$. Cela réduit l'estimateur doublement robuste à l'estimateur de pondération par score de propension $\\frac{T_iY_i}{\\hat{P}(X_i)}$, qui est correct par hypothèse. Ainsi, même si $\\hat{\\mu_1}(X_i)$ est incorrect, l'estimateur sera toujours correct, à condition que le score de propension soit correctement spécifié.\n",
    "\n",
    "Encore une fois, si vous faites davantage confiance au code qu'aux formules, voici une vérification pratique. Dans le code ci-dessous, j'ai remplacé les deux modèles de régression par une variable normale aléatoire. Il ne fait aucun doute que $\\hat{\\mu}(X_i)$ **n'est pas correctement spécifié**. Pourtant, nous verrons que l'estimation doublement robuste parvient toujours à retrouver le même $\\hat{ATE}$ d'environ 0,38 que nous avons vu précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:42.869724Z",
     "start_time": "2023-03-14T11:06:42.866481Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "def doubly_robust_wrong_model(df, X, T, Y):\n",
    "    np.random.seed(654)\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(df[X], df[T]).predict_proba(df[X])[:, 1]\n",
    "    \n",
    "    # wrong mu(x) model\n",
    "    mu0 = np.random.normal(0, 1, df.shape[0])\n",
    "    mu1 = np.random.normal(0, 1, df.shape[0])\n",
    "    return (\n",
    "        np.mean(df[T]*(df[Y] - mu1)/ps + mu1) -\n",
    "        np.mean((1-df[T])*(df[Y] - mu0)/(1-ps) + mu0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:43.004865Z",
     "start_time": "2023-03-14T11:06:42.871233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39811864040982625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubly_robust_wrong_model(data_with_categ, X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, nous pouvons utiliser le bootstrap et constater que la variance est seulement légèrement plus élevée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:07:09.710264Z",
     "start_time": "2023-03-14T11:06:43.006264Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "parallel_fn = delayed(doubly_robust_wrong_model)\n",
    "wrong_mux = Parallel(n_jobs=4)(parallel_fn(data_with_categ.sample(frac=1, replace=True), X, T, Y)\n",
    "                               for _ in range(bootstrap_sample))\n",
    "wrong_mux = np.array(wrong_mux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:07:09.715084Z",
     "start_time": "2023-03-14T11:07:09.711724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ATE 95% CI: (0.35364752721776144, 0.41978441342477585)\n",
      "Wrong Mu ATE 95% CI: (0.33863822614929406, 0.433173164584189)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original ATE 95% CI:\", (np.percentile(ates, 2.5), np.percentile(ates, 97.5)))\n",
    "print(f\"Wrong Mu ATE 95% CI:\", (np.percentile(wrong_mux, 2.5), np.percentile(wrong_mux, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, altérer uniquement le modèle de moyenne conditionnelle ne produit que des ATE légèrement différents. J'espère que je vous ai convaincu du pouvoir de l'estimation doublement robuste. Sa magie réside dans le fait qu'en inférence causale, il existe deux façons d'éliminer le biais de nos estimations causales : soit vous modélisez le mécanisme de traitement, soit vous modélisez le mécanisme de résultat. Si l'un de ces modèles est correct, vous êtes sur la bonne voie.\n",
    "\n",
    "Cependant, il y a un bémol : en pratique, il est très difficile de modéliser précisément l'un ou l'autre de ces mécanismes. Souvent, ce qui se passe, c'est que ni le score de propension ni le modèle de résultat ne sont 100 % corrects. Ils sont tous deux erronés, mais de manière différente. Dans ce cas, il n'est pas encore totalement établi [\\[1\\]](https://www.stat.cmu.edu/~ryantibs/journalclub/kang_2007.pdf) [\\[2\\]](https://arxiv.org/pdf/0804.2969.pdf) [\\[3\\]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2798744/) s'il est préférable d'utiliser un seul modèle ou l'estimation doublement robuste. Pour ma part, je préfère les utiliser car cela me donne au moins deux chances d'obtenir une estimation correcte.\n",
    "\n",
    "## Idées Clés\n",
    "\n",
    "Ici, nous avons vu une méthode simple pour combiner la régression linéaire avec le score de propension afin de produire un estimateur doublement robuste. Cet estimateur porte ce nom car il ne nécessite qu'un seul des modèles pour être correct. Si le modèle de score de propension est correct, nous pourrons identifier l'effet causal même si le modèle de résultat est erroné. À l'inverse, si le modèle de résultat est correct, nous serons également capables d'identifier l'effet causal même si le modèle de score de propension est incorrect.\n",
    "\n",
    "## Références\n",
    "\n",
    "J'aime penser à ce livre entier comme un hommage à Joshua Angrist, Alberto Abadie et Christopher Walters pour leur incroyable cours d'économétrie. La plupart des idées ici sont tirées de leurs cours à l'American Economic Association. Les regarder est ce qui me maintient sain d'esprit pendant cette année difficile de 2020.\n",
    "* [Cross-Section Econometrics](https://www.aeaweb.org/conference/cont-ed/2017-webcasts)\n",
    "* [Mastering Mostly Harmless Econometrics](https://www.aeaweb.org/conference/cont-ed/2020-webcasts)\n",
    "\n",
    "Je tiens également à référencer les livres incroyables d'Angrist. Ils m'ont montré que l'économétrie, ou 'Metrics' comme ils l'appellent, n'est pas seulement extrêmement utile mais aussi profondément amusante.\n",
    "\n",
    "* [Mostly Harmless Econometrics](https://www.mostlyharmlesseconometrics.com/)\n",
    "* [Mastering 'Metrics](https://www.masteringmetrics.com/)\n",
    "\n",
    "Ma dernière référence est le livre de Miguel Hernan et Jamie Robins. Il a été mon compagnon fidèle dans les questions causales les plus épineuses que j'ai dû résoudre.\n",
    "\n",
    "* [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)\n",
    "\n",
    "Les données utilisées ici proviennent d'une étude de Alpert, William T., Kenneth A. Couch, et Oskar R. Harmon. 2016. [\"A Randomized Assessment of Online Learning\"](https://www.aeaweb.org/articles?id=10.1257/aer.p20161057). American Economic Review, 106 (5): 378-82.\n",
    "\n",
    "![img](./data/img/poetry.png)\n",
    "\n",
    "## Contribuer\n",
    "\n",
    "*L'Inférence Causale pour les Courageux et les Vrais* est un matériel open-source sur l'inférence causale, la statistique de la science. Son objectif est d'être accessible monétairement et intellectuellement. Il utilise uniquement des logiciels gratuits basés sur Python.\n",
    "Si vous avez trouvé ce livre précieux et souhaitez le soutenir, veuillez vous rendre sur [Patreon](https://www.patreon.com/causal_inference_for_the_brave_and_true). Si vous n'êtes pas prêt à contribuer financièrement, vous pouvez également aider en corrigeant les fautes de frappe, en suggérant des modifications ou en donnant votre avis sur les passages que vous n'avez pas compris. Rendez-vous sur le repo du livre et [ouvrez une issue](https://github.com/matheusfacure/python-causality-handbook/issues). Enfin, si vous avez aimé ce contenu, veuillez le partager avec d'autres personnes qui pourraient le trouver utile et lui donner une [étoile sur GitHub](https://github.com/matheusfacure/python-causality-handbook/stargazers)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
